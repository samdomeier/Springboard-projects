{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "# general packages\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import modf\n",
    "import glob\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the models and their features\n",
    "model = pickle.load(open('models/model_1.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the feature lists for the models above for our predictions\n",
    "features = [x[:-1] for x in open('models/model_1_features.txt','r')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create functions for preparing entries for model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_bold(_str):\n",
    "    print(\"\\033[1m\" + _str + \"\\033[0m\")\n",
    "    \n",
    "\n",
    "def get_event_info(base_event, quote_event, level=None, outcome=None):\n",
    "    '''\n",
    "    - level - set to 'high','medium', or 'low'\n",
    "    - outcome - if None, then returning count of events or number of events with FF Alerts\n",
    "        - if assigned value, then returning the result actual, forecast, or sentiment\n",
    "            - this will be based on the input 'base_event','quote_event' arguments\n",
    "    '''\n",
    "    results = {'high':[],'medium':[],'low':[]}\n",
    "    for event in [base_event, quote_event]:\n",
    "        if event == 'none':\n",
    "            # all results stay empty\n",
    "            pass\n",
    "        elif 'multiple' in event:\n",
    "            # what ever impact and result is given, return 2 times that\n",
    "            items = event.split('_')\n",
    "            for key in results.keys():\n",
    "                if items[1]==key:\n",
    "                    # append this value twice for having 'multiple' same event types and results\n",
    "                    results[key].append(items[2])\n",
    "                    results[key].append(items[2])\n",
    "        else:\n",
    "            items = event.split('__')\n",
    "            for item in items:\n",
    "                it = item.split('_')\n",
    "                for key in results.keys():\n",
    "                    if it[0]==key: results[key].append(it[1])\n",
    "    # check what we are wanting to return \n",
    "    if outcome is None:\n",
    "        return len(results[level])\n",
    "    \n",
    "    # if 'outcome' is assigned a value - identify actual, forecast or sentiment result\n",
    "    if base_event==quote_event=='none': out = 0\n",
    "    else:\n",
    "        res_dict = {}\n",
    "        for key in results.keys():\n",
    "            actual = []\n",
    "            if len(results[key])==0: pass\n",
    "            else:\n",
    "                for res in results[key]:\n",
    "                    # 'better' - actual, 'right' - forecast, 'positive' - sentiment\n",
    "                    if res in ['better','right','positive']: actual.append(1)\n",
    "                    elif res in ['worse','wrong','negative']: actual.append(-1)\n",
    "            res_dict[key] = actual\n",
    "        actual_res = 3*sum(res_dict['high']) + 2*sum(res_dict['medium']) + sum(res_dict['low'])\n",
    "        if actual_res>0 and outcome=='positive': out = 1\n",
    "        elif actual_res<0 and outcome=='negative': out = 1\n",
    "        elif actual_res==0 and outcome=='neutral': out = 1\n",
    "        else: out = 0\n",
    "    return out\n",
    "\n",
    "\n",
    "def prepare_entry(entry, model_features):\n",
    "    # create a list of features to drop after feature engineering\n",
    "    to_drop = []\n",
    "    for feature in entry.columns:\n",
    "        if entry[feature].dtype == 'O' and ('__base_' in feature or '__quote_' in feature):\n",
    "            to_drop.append(feature)\n",
    "    \n",
    "    # this will include all feature engineering to the above OBJECT categorical features\n",
    "    # assuming NA values are taken care of\n",
    "    entry['ind__base_mins2next'] = entry.ind__base_mins_to_next.apply(lambda x: 2088 if x=='none' else float(x))\n",
    "    entry['ind__quote_mins2next'] = entry.ind__quote_mins_to_next.apply(lambda x: 2088 if x=='none' else float(x))\n",
    "    \n",
    "    # create binary indicator for whether or not a base/quote currency has the next event coming up (not including 2088 values)\n",
    "    entry['ind__base_nextevent'] = entry.apply(lambda x: 1 if (x['ind__base_mins2next'] >= x['ind__quote_mins2next'] and\\\n",
    "                                                     x['ind__base_mins2next']!=2088) else 0, axis=1)\n",
    "    entry['ind__quote_nextevent'] = entry.apply(lambda x: 1 if (x['ind__quote_mins2next'] >= x['ind__base_mins2next'] and\\\n",
    "                                                     x['ind__quote_mins2next']!=2088) else 0, axis=1)\n",
    "    # past event impacts    \n",
    "    entry['ind__pastimp_high'] = entry.apply(lambda x: get_event_info(x['ind__base_pastimpact'], x['ind__quote_pastimpact'], \\\n",
    "                                                             level='high'), axis=1)\n",
    "    entry['ind__pastimp_med'] = entry.apply(lambda x: get_event_info(x['ind__base_pastimpact'], x['ind__quote_pastimpact'], \\\n",
    "                                                             level='medium'), axis=1)\n",
    "    entry['ind__pastimp_low'] = entry.apply(lambda x: get_event_info(x['ind__base_pastimpact'], x['ind__quote_pastimpact'], \\\n",
    "                                                             level='low'), axis=1)\n",
    "    entry['ind__past_actual_pos'] = entry.apply(lambda x: get_event_info(x['ind__base_pastimpact'], x['ind__quote_pastimpact'], \\\n",
    "                                                                outcome='positive'), axis=1)\n",
    "    entry['ind__past_actual_neg'] = entry.apply(lambda x: get_event_info(x['ind__base_pastimpact'], x['ind__quote_pastimpact'], \\\n",
    "                                                                outcome='negative'), axis=1)\n",
    "    entry['ind__past_actual_neut'] = entry.apply(lambda x: get_event_info(x['ind__base_pastimpact'], x['ind__quote_pastimpact'], \\\n",
    "                                                                outcome='neutral'), axis=1)\n",
    "    # forecast of event impacts    \n",
    "    entry['ind__nextimp_high'] = entry.apply(lambda x: get_event_info(x['ind__base_foreimpact'], x['ind__quote_foreimpact'], \\\n",
    "                                                             level='high'), axis=1)\n",
    "    entry['ind__nextimp_med'] = entry.apply(lambda x: get_event_info(x['ind__base_foreimpact'], x['ind__quote_foreimpact'], \\\n",
    "                                                             level='medium'), axis=1)\n",
    "    entry['ind__nextimp_low'] = entry.apply(lambda x: get_event_info(x['ind__base_foreimpact'], x['ind__quote_foreimpact'], \\\n",
    "                                                             level='low'), axis=1)\n",
    "    entry['ind__next_fore_pos'] = entry.apply(lambda x: get_event_info(x['ind__base_foreimpact'], x['ind__quote_foreimpact'], \\\n",
    "                                                                outcome='positive'), axis=1)\n",
    "    entry['ind__next_fore_neg'] = entry.apply(lambda x: get_event_info(x['ind__base_foreimpact'], x['ind__quote_foreimpact'], \\\n",
    "                                                                outcome='negative'), axis=1)\n",
    "    entry['ind__next_fore_neut'] = entry.apply(lambda x: get_event_info(x['ind__base_foreimpact'], x['ind__quote_foreimpact'], \\\n",
    "                                                                outcome='neutral'), axis=1)\n",
    "    # set FF Alert features for next events\n",
    "    entry['ind__ffalert_high']=entry.apply(lambda x:get_event_info(x['ind__base_ffalert'],x['ind__quote_ffalert'],level='high'), axis=1)\n",
    "    entry['ind__ffalert_med']=entry.apply(lambda x:get_event_info(x['ind__base_ffalert'],x['ind__quote_ffalert'],level='medium'), axis=1)\n",
    "    entry['ind__ffalert_low']=entry.apply(lambda x:get_event_info(x['ind__base_ffalert'],x['ind__quote_ffalert'],level='low'), axis=1)\n",
    "    # set sentiment analysis features\n",
    "    entry['ind__pastimp_sent_pos'] = entry.apply(lambda x:get_event_info(x['ind__base_pastevent_sent'],x['ind__quote_pastevent_sent'],\\\n",
    "                                                                outcome='positive'), axis=1)\n",
    "    entry['ind__pastimp_sent_neg'] = entry.apply(lambda x:get_event_info(x['ind__base_pastevent_sent'],x['ind__quote_pastevent_sent'],\\\n",
    "                                                                outcome='negative'), axis=1)\n",
    "    entry['ind__pastimp_sent_neut'] = entry.apply(lambda x:get_event_info(x['ind__base_pastevent_sent'],x['ind__quote_pastevent_sent'],\\\n",
    "                                                                outcome='neutral'), axis=1)\n",
    "    entry['ind__nextimp_sent_pos'] = entry.apply(lambda x:get_event_info(x['ind__base_nextevent_sent'],x['ind__quote_nextevent_sent'],\\\n",
    "                                                                outcome='positive'), axis=1)\n",
    "    entry['ind__nextimp_sent_neg'] = entry.apply(lambda x:get_event_info(x['ind__base_nextevent_sent'],x['ind__quote_nextevent_sent'],\\\n",
    "                                                                outcome='negative'), axis=1)\n",
    "    entry['ind__nextimp_sent_neut'] = entry.apply(lambda x:get_event_info(x['ind__base_nextevent_sent'],x['ind__quote_nextevent_sent'],\\\n",
    "                                                                outcome='neutral'), axis=1)\n",
    "    # now we should drop all features in 'to_drop' that were used to create these features\n",
    "    entry = entry.drop(to_drop, axis=1)\n",
    "    \n",
    "    # we are going to make Low == to lowest price if not already\n",
    "    # same for High\n",
    "    entry.Low = entry.apply(lambda x: x['Low'] if x['Low'] == min([x['Low'],x['High'],x['Open'],x['Close']]) else \\\n",
    "                         min([x['Low'],x['High'],x['Open'],x['Close']]), axis=1)\n",
    "    entry.High = entry.apply(lambda x: x['High'] if x['High'] == max([x['Low'],x['High'],x['Open'],x['Close']]) else \\\n",
    "                         max([x['Low'],x['High'],x['Open'],x['Close']]), axis=1)\n",
    "    \n",
    "    # set negative values to 0 where wick height was taken\n",
    "    entry.wick_high = entry.wick_high.apply(lambda x: 0 if x<0 else x)\n",
    "    entry.wick_low = entry.wick_low.apply(lambda x: 0 if x<0 else x)\n",
    "    \n",
    "    # convert features to scale over their exchange rates to normalize the rows\n",
    "    # best way to deal with wicks -- we will try wick / range pct\n",
    "    entry['wick_low_pct'] = entry.wick_low / (entry.High - entry.Low)\n",
    "    entry['wick_high_pct'] = entry.wick_high / (entry.High - entry.Low)\n",
    "    entry['ind__midbb_pct'] = 10000*(entry.Open - entry.ind__mid_bb) / entry.Open\n",
    "    entry['ind__bbdif_pct'] = 10000*entry.ind__bb_dif / entry.ind__low_bb \n",
    "    entry['spread_pct'] = 10000*entry.spread/entry.Close\n",
    "    #entry['biddif_pct'] = entry.bid_diff/entry.spread #  -- only need one, the other is infered -- otherwise singularity potential\n",
    "    entry['askdif_pct'] = entry.ask_diff/entry.spread\n",
    "    entry['ind__bbslope_pct'] = 10000*entry.ind__midbb_slope / entry.Close\n",
    "    # np.polyfit calculates the residuals as sum of squared errors -- therefore divide by Close**2 to normalize\n",
    "    entry['ind__trendresids_pct'] = 10000*entry.ind__trend_residuals / entry.Close**2\n",
    "    \n",
    "    # drop remaining features that seperate symbols by rate\n",
    "    drop_other = ['Close_Low_avg','Close_High_avg','ind__up_bb','ind__low_bb','Close','Open','Low','High',\n",
    "                  'wick_high','wick_low','ind__bb_dif','spread','bid_diff','ask_diff','ind__midbb_slope','ind__mid_bb',\n",
    "                  'ind__trend_residuals']\n",
    "    entry = entry.drop(drop_other, axis=1)\n",
    "\n",
    "    # filter out where we did not pull currency strengths\n",
    "    entry = entry[entry.ind__base_strength!=0]\n",
    "    \n",
    "    # check entry features to see if we are missing any features needed for predicting value -- mainly symbols\n",
    "    for col in model_features:\n",
    "        if col not in entry.columns:\n",
    "            entry[col] = 0\n",
    "    # only use features in model\n",
    "    entry = entry[model_features]\n",
    "    \n",
    "    return entry\n",
    "\n",
    "    \n",
    "def predictions(model, features):\n",
    "    global time_dict\n",
    "    preds, ents = [], []\n",
    "    \n",
    "    for i,file in enumerate(glob.glob('../data/full_data/updated_apicall_data/predict/to_predict*')):\n",
    "        entry = pd.read_csv(file, index_col='date')\n",
    "        if time_dict[str(i)]!=entry.index[0]: ents.append(1)\n",
    "    if sum(ents)>0:\n",
    "        clear_output(wait=True)\n",
    "        print(datetime.datetime.now())\n",
    "        for i,file in enumerate(glob.glob('../data/full_data/updated_apicall_data/predict/to_predict*')):\n",
    "            time_dict[str(i)]=entry.index[0]\n",
    "            entry = pd.read_csv(file, index_col='date')\n",
    "            sym = entry.symbol[0]\n",
    "            print_bold(f'Last update: {sym} -- {entry.index[0]}')\n",
    "            print('---------------------------------------------')\n",
    "            # predict with all models\n",
    "            ent = prepare_entry(entry, features)\n",
    "            pred = model.predict(ent)[0]\n",
    "            res = 'call' if pred==1 else ('put' if pred==0 else 'small move.')\n",
    "            pred_prob = model.predict_proba(ent)[0][int(pred)]\n",
    "            print(res, pred_prob)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect = []\n",
    "last = datetime.datetime.now()\n",
    "# manual dict set up -- depends on number of tikers being watched\n",
    "time_dict={'0':0,'1':0,'2':0}\n",
    "i=0\n",
    "while True:\n",
    "    if i==0:predictions()\n",
    "    else: predictions(first=False)\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
